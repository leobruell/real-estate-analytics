{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05dce2f4",
   "metadata": {},
   "source": [
    "# Module 5: House Prices - Homework\n",
    "## B8474 Real Estate Analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfeb717",
   "metadata": {},
   "source": [
    "\n",
    "### General Instruction\n",
    "\n",
    "Whenever you need to change or fill the code, there will be a block starting with \"**START YOUR CODE HERE**\" and ending with \"**END YOUR CODE HERE**\". For some tasks, there may be a sample outcome before or after (i.e. what we expect from your work). Sometimes there will also be an estimate of how many lines you may need. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb516ca2",
   "metadata": {},
   "source": [
    "### Task 0: Setting up environment\n",
    "\n",
    "You are expected to set up your environment.\n",
    "\n",
    "### Task 1: Updating Zillow Data and Analysis.\n",
    "\n",
    "You are expected to update Zillow data from its website and analyze how the latest data differs from the old one.\n",
    "\n",
    "### Task 2: Building Additional Crosswalk File between CBSA and County.\n",
    "\n",
    "You are expected to build an additional crosswalk file which helps us aggregate county-level data to CBSA-level.\n",
    "\n",
    "### Task 3: Updating Price and Rent Gradient using Latest Data.\n",
    "\n",
    "You are expected to use latest data to explore price and rent gradient dynamics in the recent years and see whether the pattern continues or reverts.\n",
    "\n",
    "### Task 4: Visualizing the Relationship between Housing Price and Distance.\n",
    "\n",
    "You are expected to visualize the binscatter plots based on the latest data, and understand the evolution of housing price and rent.\n",
    "\n",
    "### Task 5: Campbell-Shiller Present Value Model: Estimation and Prediction.\n",
    "\n",
    "You are expected to re-do the data moment estimation based on latest data, and understand the gap between ex-ante and ex-post prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa18aa",
   "metadata": {},
   "source": [
    "## Task 0: Setting up environment\n",
    "\n",
    "You are expected to set up your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ffcf3d",
   "metadata": {},
   "source": [
    "**Work-flow description.** We fist need to define our workspace, where we collect all the input/output data and analysis results.In this way, cross-machine and cross-OS compatibility will greatly enhance: one only need to change one line in the code to fit different machine/OS settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a0961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys, os\n",
    "module_path = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# this is the settings file, defining some directories and relevant information\n",
    "from Code.settings import *\n",
    "# import utility functions. If there's any missing package, use conda/pip to install\n",
    "from Code.data_cleaning import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891afe50",
   "metadata": {},
   "source": [
    "## Task 1: Updating Zillow data and analysis.\n",
    "\n",
    "You are expected to update Zillow data from its website and analyze how the latest data differs from the old one.\n",
    "\n",
    "### Task 1.1 Updating Zillow data from its website\n",
    "\n",
    "Go to https://www.zillow.com/research/data/ and download the latest ZHVI (price index) and ZORI (rent index) from Zillow. Note that the `Data Type` for ZHVI should be `ZHVI All Homes (SFR, Condo/Co-op) Time Series, Smoothed, Seasonally Adjusted($)` and for ZORI should be `ZORI (Smoothed, Seasonally Adjusted): All Homes Plus Multifamily Time Series ($)`. Both of them should be in zip level.\n",
    "\n",
    "\n",
    "**Go to https://www.zillow.com/research/data/ and download the latest ZHVI (price index) and ZORI (rent index) from Zillow.**\n",
    "| Housing Data | Data Type | Geography |\n",
    "| :----: | :--------- | :---------: |\n",
    "| ZHVI | ZHVI All Homes (SFR, Condo/Co-op) Time Series, Smoothed, Seasonally Adjusted(\\$) | ZIP Code |\n",
    "| ZORI | ZORI (Smoothed, Seasonally Adjusted): All Homes Plus Multifamily Time Series (\\$) | ZIP Code |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d656f74",
   "metadata": {},
   "source": [
    "### Taks 1.2 Comparing the latest data to the old ones\n",
    "\n",
    "Load the data you just downloaded in Python. Compare each of them to its old version (the data we used during the lecture). Check the number of observations, coverage, and values. What do you find?\n",
    "\n",
    "*Hint: Below is a sample output for this question (with wrong numbers).*\n",
    "```\n",
    "Loading new and old ZHVI...\n",
    "Check shape...\n",
    "(30466, 273) (30329, 309)\n",
    "Check # zip codes in new df but not in old df:  466\n",
    "Check # zip codes in old df but not in new df:  329\n",
    "Check for one common observation's ZHVI value: \n",
    "Zip code: 10026\n",
    "ZHVI in new: 238865.0\n",
    "ZHVI in old: 246441.0\n",
    "```\n",
    "*You are not required to follow the format exactly, but these are essentially what we are looking for.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaee43cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZHVI:\n",
      "new_zhvi shape: (26353, 299). old_zhvi shape: (30329, 309).\n",
      "Check # zip codes in new df but not in old df: 544\n",
      "Check # zip codes in old df but not in new df: 4520\n",
      "Check value in new ZHVI for 10025 (my zip code) in 2015-1: 960388.4342808244\n",
      "Check value in old ZHVI for 10025 (my zip code) in 2015-1: 1270318.0\n",
      "------------------------\n",
      "ZORI:\n",
      "new_zori shape: (6663, 119). old_zori shape: (2263, 88).\n",
      "Check # zip codes in new df but not in old df: 4433\n",
      "Check # zip codes in old df but not in new df: 33\n",
      "Check value in new ZORI for 10025 (my zip code) in 2015-1: 3050.9336968112943\n",
      "Check value in old ZORI for 10025 (my zip code) in 2015-1: 3196.0\n"
     ]
    }
   ],
   "source": [
    "# ========== START YOUR CODE HERE ==========\n",
    "#Load the data\n",
    "new_zhvi = pd.read_csv('Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv')\n",
    "new_zori = pd.read_csv('Zip_zori_uc_sfrcondomfr_sm_month.csv')\n",
    "old_zhvi = pd.read_csv('/home/leo/repos/real-estate-analytics/Module 5 - House Prices/Data/Zillow/Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv')\n",
    "old_zori = pd.read_csv('/home/leo/repos/real-estate-analytics/Module 5 - House Prices/Data/Zillow/Zip_ZORI_AllHomesPlusMultifamily_SSA.csv')\n",
    "\n",
    "# Compare old and new\n",
    "print(\"ZHVI:\")\n",
    "print(\"new_zhvi shape: {}. old_zhvi shape: {}.\".format(new_zhvi.shape, old_zhvi.shape))\n",
    "print(\"Check # zip codes in new df but not in old df: {}\".format(new_zhvi[~new_zhvi['RegionName'].isin(old_zhvi['RegionName'])].shape[0]))\n",
    "print(\"Check # zip codes in old df but not in new df: {}\".format(old_zhvi[~old_zhvi['RegionName'].isin(new_zhvi['RegionName'])].shape[0]))\n",
    "print('Check value in new ZHVI for 10025 (my zip code) in 2015-1: {}'.format(new_zhvi.loc[new_zhvi['RegionName'] == 10025,'2015-01-31'].values[0]))\n",
    "print('Check value in old ZHVI for 10025 (my zip code) in 2015-1: {}'.format(old_zhvi.loc[old_zhvi['RegionName'] == 10025,'2015-01-31'].values[0]))\n",
    "print(\"------------------------\")\n",
    "print(\"ZORI:\")\n",
    "print(\"new_zori shape: {}. old_zori shape: {}.\".format(new_zori.shape, old_zori.shape))\n",
    "print(\"Check # zip codes in new df but not in old df: {}\".format(new_zori[~new_zori['RegionName'].isin(old_zori['RegionName'])].shape[0]))\n",
    "print(\"Check # zip codes in old df but not in new df: {}\".format(old_zori[~old_zori['RegionName'].isin(new_zori['RegionName'])].shape[0]))\n",
    "print('Check value in new ZORI for 10025 (my zip code) in 2015-1: {}'.format(new_zori.loc[new_zori['RegionName'] == 10025,'2015-01-31'].values[0]))\n",
    "print('Check value in old ZORI for 10025 (my zip code) in 2015-1: {}'.format(old_zori.loc[old_zori['RegionName'] == 10025,'2015-01'].values[0]))\n",
    "# =========== END YOUR CODE HERE ==========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e0f71",
   "metadata": {},
   "source": [
    "### Task 1.3 Updating the pre-processing function\n",
    "Since we have observations for a longer time horizon, changes may be necessary to also include the data from recent months. \n",
    "\n",
    "You are expected to make changes on the pre-processing code in our lecture to incorporate latest observations \n",
    "- We want the sample start to be 2018 instead. And the sample end to be Jan 2024 or later.\n",
    "- Hint: when you hit bugs, run the code line by line and adjust those that aren't compatible with the latest data\n",
    "\n",
    "```python\n",
    "# Read house price data (zhvi), monthly panel of ZIPs\n",
    "df_zhvi = pd.read_csv(os.path.join(zillow_dir_week2, \"Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv\"), dtype={\"RegionName\": str})\n",
    "# fill in the leading 0s in the zip code\n",
    "df_zhvi[\"RegionName\"] = df_zhvi[\"RegionName\"].apply(lambda x: \"0\" * (5 - len(x)) + x)\n",
    "df_zhvi.drop(columns=['SizeRank', 'RegionID', 'RegionType', 'StateName', 'State', 'City', 'Metro', 'CountyName'], inplace=True)\n",
    "# rename the columns to keep only the year and month\n",
    "df_zhvi.columns = [_ for _ in df_zhvi.keys()[:1]] + [_[:7] for _ in df_zhvi.keys()[1:]]\n",
    "# reshape the data from wide to long for the months\n",
    "df_zhvi = pd.wide_to_long(df_zhvi, [str(_) for _ in range(1996, 2021)], i=\"RegionName\", j=\"month\", sep=\"-\").reset_index(drop=False)\n",
    "# add prefix \"ZHVI-\" to the column names that will be used as stubnames in pd.wide_to_long()\n",
    "df_zhvi.columns = [_ for _ in df_zhvi.keys()[:2]] + [\"ZHVI-\" + _[:7] for _ in df_zhvi.keys()[2:]]\n",
    "# reshape the data from wide to long for the years\n",
    "df_zhvi = pd.wide_to_long(df_zhvi, [\"ZHVI\"], i=[\"RegionName\", \"month\"], j=\"year\", sep=\"-\").reset_index(drop=False)\n",
    "\n",
    "# Read rent data (zori), monthly panel of ZIPs\n",
    "df_zori = pd.read_csv(os.path.join(zillow_dir_week2, \"Zip_ZORI_AllHomesPlusMultifamily_SSA.csv\"), dtype={\"RegionName\": str})\n",
    "# fill in the leading 0s in the zip code\n",
    "df_zori[\"RegionName\"] = df_zori[\"RegionName\"].apply(lambda x: \"0\" * (5 - len(x)) + x)\n",
    "df_zori.drop(columns=['RegionID', 'SizeRank', 'MsaName'], inplace=True)\n",
    "# convert the wide format to long format\n",
    "df_zori = pd.wide_to_long(df_zori, [str(_) for _ in range(2014, 2021)], i=\"RegionName\", j=\"month\", sep=\"-\").reset_index(drop=False)\n",
    "df_zori.columns = [_ for _ in df_zori.keys()[:2]] + [\"ZORI-\" + _[:7] for _ in df_zori.keys()[2:]]\n",
    "df_zori = pd.wide_to_long(df_zori, [\"ZORI\"], i=[\"RegionName\", \"month\"], j=\"year\", sep=\"-\").reset_index(drop=False)\n",
    "\n",
    "# Merge price and rent data on ZIP-month-year\n",
    "df = pd.merge(df_zhvi, df_zori, how=\"outer\", on=[\"RegionName\", \"month\", \"year\"])\n",
    "df.rename(columns={\"RegionName\": \"ZIP\"}, inplace=True)\n",
    "\n",
    "df.to_pickle(os.path.join(save_dir_week2, \"zillow_202403.pkl\"))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192f627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumption: 58.18715167045593s\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()  # record the current time\n",
    "\n",
    "# ========== START YOUR CODE HERE ==========\n",
    "# ZHVI\n",
    "# fill in the leading 0s in the zip code\n",
    "new_zhvi[\"RegionName\"] = new_zhvi[\"RegionName\"].astype(str).apply(lambda x: \"0\" * (5 - len(x)) + x)\n",
    "new_zhvi.drop(columns=['SizeRank', 'RegionID', 'RegionType', 'StateName', 'State', 'City', 'Metro', 'CountyName'], inplace=True)\n",
    "new_zhvi.columns = ['RegionName'] + [col[:7] for col in new_zhvi.columns[1:]]\n",
    "# rename the columns to keep only the year and month\n",
    "new_zhvi.columns = [_ for _ in new_zhvi.keys()[:1]] + [_[:7] for _ in new_zhvi.keys()[1:]]\n",
    "# reshape the data from wide to long for the months\n",
    "new_zhvi = pd.wide_to_long(new_zhvi, [str(_) for _ in range(1996, 2025)], i=\"RegionName\", j=\"month\", sep=\"-\").reset_index(drop=False)\n",
    "# add prefix \"ZHVI-\" to the column names that will be used as stubnames in pd.wide_to_long()\n",
    "new_zhvi.columns = [_ for _ in new_zhvi.keys()[:2]] + [\"ZHVI-\" + _[:7] for _ in new_zhvi.keys()[2:]]\n",
    "# # reshape the data from wide to long for the years\n",
    "new_zhvi = pd.wide_to_long(new_zhvi, [\"ZHVI\"], i=[\"RegionName\", \"month\"], j=\"year\", sep=\"-\").reset_index(drop=False)\n",
    "\n",
    "# ZORI\n",
    "# fill in the leading 0s in the zip code\n",
    "new_zori[\"RegionName\"] = new_zori[\"RegionName\"].astype(str).apply(lambda x: \"0\" * (5 - len(x)) + x)\n",
    "new_zori.drop(columns=['SizeRank', 'RegionID', 'RegionType', 'StateName', 'State', 'City', 'Metro', 'CountyName'], inplace=True)\n",
    "new_zori.columns = ['RegionName'] + [col[:7] for col in new_zori.columns[1:]]\n",
    "# # convert the wide format to long format\n",
    "new_zori = pd.wide_to_long(new_zori, [str(_) for _ in range(2014, 2025)], i=\"RegionName\", j=\"month\", sep=\"-\").reset_index(drop=False)\n",
    "new_zori.columns = [_ for _ in new_zori.keys()[:2]] + [\"ZORI-\" + _[:7] for _ in new_zori.keys()[2:]]\n",
    "new_zori = pd.wide_to_long(new_zori, [\"ZORI\"], i=[\"RegionName\", \"month\"], j=\"year\", sep=\"-\").reset_index(drop=False)\n",
    "\n",
    "# Merge price and rent data on ZIP-month-year\n",
    "df = pd.merge(new_zhvi, new_zori, how=\"outer\", on=[\"RegionName\", \"month\", \"year\"])\n",
    "df.rename(columns={\"RegionName\": \"ZIP\"}, inplace=True)\n",
    "df = df[df['year'] > 2017]\n",
    "# # =========== END YOUR CODE HERE ===========\n",
    "df.to_pickle(os.path.join(save_dir_week2, \"zillow_202403.pkl\"))\n",
    "\n",
    "print(\"Time consumption: {}s\".format(time.time() - time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e71cb",
   "metadata": {},
   "source": [
    "## Task 2: Building Additional Crosswalk File between CBSA and County.\n",
    "\n",
    "You are expected to complete the function to build county2cbsa crosswalk data frame. This data frame indents to match each county to MSAs with probabilities respectively. This crosswalk file will be helpful for aggregating county-level Wharton regulartory index to MSA level. A random sample of the alleged crosswalk file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e07927eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBSA</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TOT_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10100</td>\n",
       "      <td>46013</td>\n",
       "      <td>0.937332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10100</td>\n",
       "      <td>46115</td>\n",
       "      <td>0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10100</td>\n",
       "      <td>46107</td>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10100</td>\n",
       "      <td>46091</td>\n",
       "      <td>0.001041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10100</td>\n",
       "      <td>46089</td>\n",
       "      <td>0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10100</td>\n",
       "      <td>46129</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10100</td>\n",
       "      <td>46045</td>\n",
       "      <td>0.053148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10100</td>\n",
       "      <td>46037</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10100</td>\n",
       "      <td>46025</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10100</td>\n",
       "      <td>46049</td>\n",
       "      <td>0.001470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CBSA COUNTY  TOT_RATIO\n",
       "0  10100  46013   0.937332\n",
       "8  10100  46115   0.002194\n",
       "7  10100  46107   0.000819\n",
       "6  10100  46091   0.001041\n",
       "5  10100  46089   0.002554\n",
       "9  10100  46129   0.000908\n",
       "3  10100  46045   0.053148\n",
       "2  10100  46037   0.000387\n",
       "1  10100  46025   0.000147\n",
       "4  10100  46049   0.001470"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(os.path.join(save_dir_week2, \"cbsa_county_crosswalk.pkl\")).sort_values([\"CBSA\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "24dc4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_county2cbsa_crosswalk():\n",
    "    \"\"\"util function, build county2cbsa crosswalk\"\"\"\n",
    "    cbsa2zip = pd.read_excel(cbsa2zip_dir, dtype=str)\n",
    "    zip2county = pd.read_excel(zip2county_dir, dtype=str)\n",
    "    \n",
    "    # ========== START YOUR CODE HERE ==========\n",
    "    # Set TOT_RATIO to float datatype: \n",
    "    zip2county['TOT_RATIO'] = zip2county['TOT_RATIO'].astype(float)\n",
    "    cbsa2zip['TOT_RATIO'] = cbsa2zip['TOT_RATIO'].astype(float)\n",
    "    # Merge County and County tot info to cbsa df: \n",
    "    df = cbsa2zip.merge(zip2county[['ZIP','COUNTY','TOT_RATIO']], on='ZIP',how='left')\n",
    "    # Create new tot_ratio by multiplying the two tots together to get the correct weights for the cbsa level: \n",
    "    df['TOT_RATIO'] = df['TOT_RATIO_x'] * df['TOT_RATIO_y']\n",
    "    # Group by CBSA and COUNTY, summing TOT Ratio to get the correct contribution of the county to the CBSA\n",
    "    df = df.groupby(['CBSA','COUNTY'])['TOT_RATIO'].sum().reset_index()\n",
    "    # =========== END YOUR CODE HERE ===========\n",
    "    \n",
    "    df.to_pickle(os.path.join(save_dir_week2, \"cbsa_county_crosswalk.pkl\"))\n",
    "    df.to_excel(os.path.join(save_dir_week2, \"cbsa_county_crosswalk.xlsx\"), index=False)\n",
    "\n",
    "build_county2cbsa_crosswalk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb49bd",
   "metadata": {},
   "source": [
    "## Task 3: Updating Price and Rent Gradient using Latest Data.\n",
    "\n",
    "You are expected to use latest data (`\"zillow_202403.pkl\"`) to explore price and rent gradient dynamics in the recent years and see whether the pattern continues or reverts.\n",
    "\n",
    "### Task 3.1: Building up zip panel\n",
    "Refer to the relevant section in lecture note, and re-build zip panel for gradient estimation with the latest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Zillow data\n",
    "df = pd.read_pickle(os.path.join(save_dir_week2, \"zillow_202403.pkl\"))\n",
    "\n",
    "\n",
    "# ========== START YOUR CODE HERE ==========\n",
    "pass\n",
    "# =========== END YOUR CODE HERE ===========\n",
    "\n",
    "# save df to file for gradient estimation\n",
    "df.to_pickle(os.path.join(save_dir_week2, \"zip_panel_grad_202403.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8c802",
   "metadata": {},
   "source": [
    "### Task 3.2: Estimation of gradient change and visualization\n",
    "\n",
    "Refer to Section 2.1 in the lecture and re-do the exercise to see what happen in latest data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== START YOUR CODE HERE ==========\n",
    "pass\n",
    "# =========== END YOUR CODE HERE ==========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16f8d5",
   "metadata": {},
   "source": [
    "### Task 3.3: Analysis\n",
    "\n",
    "Compare the updated picture with the one in class, what do you find? More specifically, for overlapping time span, do these two plots have the same values/interval estimates? For non-overlapping time span, does the trend we found in class continue or revert?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228b062",
   "metadata": {},
   "source": [
    "**Your Answer:** [ENTER YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc85db3",
   "metadata": {},
   "source": [
    "## Task 4: Visualizing the Relationship between Housing Price and Distance.\n",
    "\n",
    "You are expected to plot the ensembled picture you saw in the lecture, which characterize the relationship between housing price and distance. The only change is that you will have more years. Recall that there are two elements in the ensembled plots:\n",
    "\n",
    "1) A scatter plot whose `x` axis is log distance and `y` axis is log price. You need to plot the data points for Dec. 2019, Dec. 2020, Dec.2021, Dec.2022, and Dec.2023, with different colors.\n",
    "\n",
    "2) Binscatter plot (see [this link](https://michaelstepner.com/binscatter/) for detailed introduction of binscatter). The Python realization of binscatter plot and its usage is inside `binscatter_func.py`. The control variables are: `'cns_median_hh_inc'`, `'cns_median_age'`, `'cns_black_ratio'`, `'cns_rich_ratio'` from Census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from Code.binscatter_func import *\n",
    "\n",
    "df = pd.read_pickle(os.path.join(save_dir_week2, \"zip_panel_grad_202403.pkl\"))\n",
    "top30msa = pd.read_csv(os.path.join(data_dir_week2, \"top30MSA.txt\"), dtype=str)\n",
    "\n",
    "# select ZIP codes in the 30 largest MSAs\n",
    "df = df[df[\"CBSA\"].apply(lambda x: x in top30msa.CBSA.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1eab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== START YOUR CODE HERE ==========\n",
    "# ... reshape the data ...\n",
    "\n",
    "# axes.scatter(...)\n",
    "# ...\n",
    "# axes.binscatter(...)\n",
    "# ...\n",
    "# =========== END YOUR CODE HERE ===========\n",
    "\n",
    "\n",
    "axes.set_xlabel('log-distance between a zip to corresponding city hall')\n",
    "axes.set_ylabel('log-price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d351d65",
   "metadata": {},
   "source": [
    "## Task 5: Campbell-Shiller Present Value Model: Estimation and Prediction.\n",
    "\n",
    "During the lecture, we learned how to estimate the data moments for Campbell-Shiller model, and what the model predicts when the pandemic shock is either assumed to be transitory or permanent. Now we have three more years of data on the realized growth rate of rents in urban and suburban ZIP codes since that initial analysis. Tabulate urban minus suburban rent growth between Dec 2020 and Dec 2023 **for each CBSA**. Which model fits the data the best? The transitory or permanent shock model?\n",
    "\n",
    "Hint: you first need to calculate the realized average rent growth (weighted by cns_pop), then read the predictions from `\"present_model_prediction.pkl\"`, and finally report the best model for each CBSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(save_dir_week2, \"zip_panel_grad_202403.pkl\"))\n",
    "top30msa = pd.read_csv(os.path.join(data_dir_week2, \"top30MSA.txt\"), dtype=str)\n",
    "\n",
    "# select ZIP codes in the 30 largest MSAs\n",
    "df = df[df[\"CBSA\"].apply(lambda x: x in top30msa.CBSA.to_list())]\n",
    "\n",
    "# ========== START YOUR CODE HERE ==========\n",
    "\n",
    "\n",
    "# =========== END YOUR CODE HERE ===========\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8520b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
